{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45e29137-7ff8-490a-899d-79429c4e91d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, confusion_matrix)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, LSTM, GRU, SimpleRNN, Flatten, Dropout, Reshape\n",
    "from keras.optimizers import Adam\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e62999a5-f6f7-47a5-9b73-01c166d1efa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\user\\Desktop\\Project\\EXPERIMENTS\\revised-data\\audio_features_cp.csv\")\n",
    "\n",
    "# Feature selection\n",
    "features = [\n",
    "    'mfcc_1', 'mfcc_2', 'mfcc_3', 'mfcc_4', 'mfcc_5', 'mfcc_6', 'mfcc_7', 'mfcc_8', \n",
    "    'mfcc_9', 'mfcc_10', 'mfcc_11', 'mfcc_12', 'mfcc_13', 'spectral_centroid', \n",
    "    'spectral_bandwidth', 'zero_crossing_rate', 'spectrogram_mean', \n",
    "    'spectrogram_median', 'spectrogram_variance'\n",
    "]\n",
    "label = 'label'\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df[features] = scaler.fit_transform(df[features])\n",
    "\n",
    "# Split data\n",
    "X = df[features].values\n",
    "y = df[label].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshaping for each model\n",
    "X_train_rnn = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "X_test_rnn = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "\n",
    "X_train_cnn1d = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test_cnn1d = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "X_train_cnn2d = X_train.reshape(X_train.shape[0], X_train.shape[1], 1, 1)\n",
    "X_test_cnn2d = X_test.reshape(X_test.shape[0], X_test.shape[1], 1, 1)\n",
    "\n",
    "# Define models\n",
    "def create_rnn_model(input_shape):\n",
    "    model = Sequential([\n",
    "        SimpleRNN(128, activation='relu', input_shape=input_shape, return_sequences=False),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def create_gru_model(input_shape):\n",
    "    model = Sequential([\n",
    "        GRU(128, activation='relu', input_shape=input_shape, return_sequences=False),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def create_lstm_model(input_shape):\n",
    "    model = Sequential([\n",
    "        LSTM(128, activation='relu', input_shape=input_shape, return_sequences=False),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def create_cnn1d_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Conv1D(64, 3, activation='relu', input_shape=input_shape),\n",
    "        MaxPooling1D(2),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def create_cnn2d_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Reshape((input_shape[0], input_shape[1], 1), input_shape=input_shape),\n",
    "        Conv2D(32, kernel_size=(3, 1), activation='relu', padding='same'),\n",
    "        MaxPooling2D(pool_size=(2, 1), padding='same'),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Training and evaluation function\n",
    "def train_and_evaluate_hybrid_model(n_iterations):\n",
    "    evaluation = pd.DataFrame(columns=[\"Iteration\", \"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\"])\n",
    "    \n",
    "    for i in range(n_iterations):\n",
    "        print(f\"Iteration {i + 1}/{n_iterations}\")\n",
    "\n",
    "        # Train each model\n",
    "        rnn_model = create_rnn_model(X_train_rnn.shape[1:])\n",
    "        rnn_model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        rnn_model.fit(X_train_rnn, y_train, epochs=100, verbose=0)\n",
    "        rnn_predictions = (rnn_model.predict(X_test_rnn) > 0.5).astype(int)\n",
    "\n",
    "        gru_model = create_gru_model(X_train_rnn.shape[1:])\n",
    "        gru_model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        gru_model.fit(X_train_rnn, y_train, epochs=100, verbose=0)\n",
    "        gru_predictions = (gru_model.predict(X_test_rnn) > 0.5).astype(int)\n",
    "\n",
    "        lstm_model = create_lstm_model(X_train_rnn.shape[1:])\n",
    "        lstm_model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        lstm_model.fit(X_train_rnn, y_train, epochs=100, verbose=0)\n",
    "        lstm_predictions = (lstm_model.predict(X_test_rnn) > 0.5).astype(int)\n",
    "\n",
    "        cnn1d_model = create_cnn1d_model(X_train_cnn1d.shape[1:])\n",
    "        cnn1d_model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        cnn1d_model.fit(X_train_cnn1d, y_train, epochs=100, verbose=0)\n",
    "        cnn1d_predictions = (cnn1d_model.predict(X_test_cnn1d) > 0.5).astype(int)\n",
    "\n",
    "        cnn2d_model = create_cnn2d_model(X_train_cnn2d.shape[1:])\n",
    "        cnn2d_model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        cnn2d_model.fit(X_train_cnn2d, y_train, epochs=100, verbose=0)\n",
    "        cnn2d_predictions = (cnn2d_model.predict(X_test_cnn2d) > 0.5).astype(int)\n",
    "\n",
    "        # Hybrid predictions using majority voting\n",
    "        hybrid_predictions = np.round((rnn_predictions + gru_predictions + lstm_predictions + cnn1d_predictions+cnn2d_predictions)/5).astype(int)\n",
    "\n",
    "        # Evaluation metrics\n",
    "        accuracy = accuracy_score(y_test, hybrid_predictions)\n",
    "        precision = precision_score(y_test, hybrid_predictions, zero_division=1)\n",
    "        recall = recall_score(y_test, hybrid_predictions, zero_division=1)\n",
    "        f1 = f1_score(y_test, hybrid_predictions, zero_division=1)\n",
    "\n",
    "        evaluation = evaluation._append({\n",
    "            \"Iteration\": i + 1,\n",
    "            \"Model\": \"Hybrid (RNN + GRU + LSTM + CNN 1D + CNN 2D)\",\n",
    "            \"Accuracy\": accuracy,\n",
    "            \"Precision\": precision,\n",
    "            \"Recall\": recall,\n",
    "            \"F1-Score\": f1\n",
    "        }, ignore_index=True)\n",
    "\n",
    "    # Save results\n",
    "    return evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63310d99-e3c3-465c-a58b-b7e8b71dbd9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step  \n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\reshaping\\reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "  Iteration                                        Model  Accuracy  Precision  \\\n",
      "0         1  Hybrid (RNN + GRU + LSTM + CNN 1D + CNN 2D)  0.959091   0.965015   \n",
      "\n",
      "     Recall  F1-Score  \n",
      "0  0.956647  0.960813  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_8760\\1216176777.py:120: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  evaluation = evaluation._append({\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "n_iterations = 1\n",
    "results = train_and_evaluate_hybrid_model(n_iterations)\n",
    "results.to_csv(\"hybrid_model_results.csv\", index=False)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023c53b7-ca71-4e0b-9f7a-625bf869bd3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
