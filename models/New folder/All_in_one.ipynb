{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3b3bfe9b-4048-4d7c-a247-b3ed13c4df18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.models as models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, SimpleRNN, Dropout, GRU\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, confusion_matrix, log_loss, mean_absolute_error, mean_squared_error, matthews_corrcoef\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import librosa\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f5517f86-bf84-41a8-9e70-311118f8af13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\user\\Desktop\\Project\\EXPERIMENTS\\revised-data\\audio_features_cp.csv\")\n",
    "\n",
    "# Define feature columns and target column\n",
    "x_cols = ['mfcc_1', 'mfcc_2', 'mfcc_3', 'mfcc_4', 'mfcc_5', 'mfcc_6', 'mfcc_7', 'mfcc_8', \n",
    "           'mfcc_9', 'mfcc_10', 'mfcc_11', 'mfcc_12', 'mfcc_13', 'spectral_centroid', \n",
    "           'spectral_bandwidth', 'zero_crossing_rate' , 'spectrogram_mean' , 'spectrogram_median' , 'spectrogram_variance']\n",
    "y_cols = ['label']\n",
    "\n",
    "# Normalize the feature data to range [0,1] using MinMaxScaler\n",
    "SMM = MinMaxScaler(feature_range=(0, 1))\n",
    "df[x_cols] = SMM.fit_transform(df[x_cols])\n",
    "\n",
    "# Split data into features and labels\n",
    "X = df[x_cols].values  # Convert to NumPy array\n",
    "y = df[y_cols].values.ravel()  # Convert to 1D array\n",
    "\n",
    "# Train-test split (20% test set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "X_train_rnn = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test_rnn = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "50f256f9-80ca-41bb-8950-e2a8fe21de6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Defining the models:\n",
    "#Logistic Regression\n",
    "model_0 = LogisticRegression(C=1.0, solver='lbfgs', max_iter=500, random_state=42)\n",
    "#Decision Tree\n",
    "model_1 = DecisionTreeClassifier(criterion='entropy', max_depth=10, min_samples_split=5, min_samples_leaf=2, random_state=42)\n",
    "#Random Forest\n",
    "model_2 = RandomForestClassifier(criterion='entropy', n_estimators=500, max_depth=10, min_samples_split=5, min_samples_leaf=2, random_state=42)\n",
    "#Naive Bayes\n",
    "model_3 = GaussianNB()\n",
    "#SVM\n",
    "model_4 = SVC(C=1.0, kernel='rbf', gamma='scale', probability=True)\n",
    "#KNN\n",
    "model_5 = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2)\n",
    "#GBC\n",
    "model_6 = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, min_samples_split=5, min_samples_leaf=2, random_state=42)\n",
    "#NN\n",
    "model_7 = Sequential()\n",
    "model_7.add(Dense(128, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "model_7.add(Dropout(0.3))\n",
    "model_7.add(Dense(64, activation='relu'))\n",
    "model_7.add(Dropout(0.3))\n",
    "model_7.add(Dense(1, activation='sigmoid'))\n",
    "model_7.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "#CNN\n",
    "model_8 = Sequential()\n",
    "model_8.add(layers.InputLayer(input_shape=(19,)))\n",
    "model_8.add(layers.Reshape((19, 1, 1)))\n",
    "model_8.add(layers.Conv2D(32, kernel_size=(3, 1), activation='relu', padding='same'))\n",
    "model_8.add(layers.MaxPooling2D(pool_size=(2, 1), padding='same'))\n",
    "model_8.add(layers.Conv2D(64, kernel_size=(3, 1), activation='relu', padding='same'))\n",
    "model_8.add(layers.MaxPooling2D(pool_size=(2, 1), padding='same'))\n",
    "model_8.add(layers.Flatten())\n",
    "model_8.add(layers.Dense(128, activation='relu'))\n",
    "model_8.add(layers.Dropout(0.2))\n",
    "model_8.add(layers.Dense(1, activation='sigmoid'))\n",
    "model_8.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "#RNN\n",
    "model_9 = Sequential()\n",
    "model_9.add(SimpleRNN(50, input_shape=(1, 19), activation='relu'))\n",
    "model_9.add(Dropout(0.3))\n",
    "model_9.add(Dense(1, activation='sigmoid'))\n",
    "model_9.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "#LSTM\n",
    "model_10 = Sequential()\n",
    "model_10.add(LSTM(128, input_shape=(X_train_rnn.shape[1], X_train_rnn.shape[2]), activation='relu', return_sequences=False))\n",
    "model_10.add(Dropout(0.3))\n",
    "model_10.add(Dense(64, activation='relu'))\n",
    "model_10.add(Dropout(0.3))\n",
    "model_10.add(Dense(1, activation='sigmoid'))  # For binary classification\n",
    "model_10.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "#GRU\n",
    "model_11 = Sequential()\n",
    "model_11.add(GRU(128, input_shape=(X_train_rnn.shape[1], X_train_rnn.shape[2]), activation='relu', return_sequences=False))\n",
    "model_11.add(Dropout(0.3))\n",
    "model_11.add(Dense(64, activation='relu'))\n",
    "model_11.add(Dropout(0.3))\n",
    "model_11.add(Dense(1, activation='sigmoid'))\n",
    "model_11.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "05da2a76-a34a-425f-bef7-3bba7158cc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "models=[model_0, model_1, model_2 , model_3, model_4, model_5, model_6, model_7, model_8, model_9, model_10, model_11]\n",
    "model=model_0\n",
    "conf_cols=['model_name','true_negative','false_positive','false_negative','true_positive']\n",
    "eval_cols=['model_name','accuracy','f1','precision','recall','roc_auc','log_loss_val','mae','mse','mcc']\n",
    "global conf_matrix_df\n",
    "global evaluation\n",
    "evaluation = pd.DataFrame(columns=eval_cols)\n",
    "conf_matrix_df = pd.DataFrame(columns=conf_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7a831459-5707-4b73-abfa-cba421b974f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval3d(models,model,sel_model,epoch,loopno,X_train,y_train,X_test,y_test,X_train_rnn,X_test_rnn,evaluation,conf_matrix_df):\n",
    "    X= X_train_rnn\n",
    "    y= y_train\n",
    "    X_test=X_test_rnn\n",
    "    if sel_model == models[9]:\n",
    "        model=models[9]\n",
    "    elif sel_model == models[10]:\n",
    "        model=models[10]\n",
    "    elif sel_model == models[11]:\n",
    "        model=models[11]\n",
    "    else:\n",
    "        print('Error')\n",
    "        return\n",
    "    for loop in range(loopno):\n",
    "        model.fit(X,y, epochs=epoch, batch_size=32)\n",
    "        y_pred_prob = model.predict(X_test_rnn)\n",
    "        prediction = (y_pred_prob > 0.5).astype(\"int32\")\n",
    "        accuracy = accuracy_score(y_test, prediction)\n",
    "        f1 = f1_score(y_test, prediction)\n",
    "        precision = precision_score(y_test, prediction)\n",
    "        recall = recall_score(y_test, prediction)\n",
    "        roc_auc = roc_auc_score(y_test, prediction)\n",
    "        log_loss_val = log_loss(y_test, prediction)\n",
    "        mae = mean_absolute_error(y_test, prediction)\n",
    "        mse = mean_squared_error(y_test, prediction)\n",
    "        mcc = matthews_corrcoef(y_test, prediction)\n",
    "        evaluation = evaluation._append({'model_name':str(sel_model),'accuracy': accuracy, 'f1': f1, 'precision': precision, 'recall': recall, 'roc_auc': roc_auc, 'log_loss_val': log_loss_val, 'mae': mae, 'mse': mse, 'mcc': mcc}, ignore_index=True)\n",
    "        conf_matrix = confusion_matrix(y_test, prediction)\n",
    "        tn = conf_matrix[0][0]\n",
    "        fn = conf_matrix[1][0]\n",
    "        tp = conf_matrix[1][1]\n",
    "        fp = conf_matrix[0][1]\n",
    "        conf_matrix_df = conf_matrix_df._append({'model': sel_model, 'true_negative': tn, 'false_positive': fp, 'false_negative': fn, 'true_positive': tp}, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3921737d-5326-4fd1-b1f4-974042c19d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaldl(models,model,sel_model,epoch,loopno,X_train,y_train,X_test,y_test,X_train_rnn,X_test_rnn,evaluation,conf_matrix_df):\n",
    "    X= X_train\n",
    "    y= y_train\n",
    "    if sel_model == models[7]:\n",
    "        model=models[7]\n",
    "    elif sel_model == models[8]:\n",
    "        model=models[8]\n",
    "    else:\n",
    "        eval3d(models,model,sel_model,epoch,loopno,X_train,y_train,X_test,y_test,X_train_rnn,X_test_rnn,evaluation,conf_matrix_df)\n",
    "        return\n",
    "    for loop in range(loopno):\n",
    "        model.fit(X,y, epochs=epoch, batch_size=32)\n",
    "        y_pred_prob = model.predict(X_test)\n",
    "        prediction = (y_pred_prob > 0.5).astype(\"int32\")\n",
    "        accuracy = accuracy_score(y_test, prediction)\n",
    "        f1 = f1_score(y_test, prediction)\n",
    "        precision = precision_score(y_test, prediction)\n",
    "        recall = recall_score(y_test, prediction)\n",
    "        roc_auc = roc_auc_score(y_test, prediction)\n",
    "        log_loss_val = log_loss(y_test, prediction)\n",
    "        mae = mean_absolute_error(y_test, prediction)\n",
    "        mse = mean_squared_error(y_test, prediction)\n",
    "        mcc = matthews_corrcoef(y_test, prediction)\n",
    "        evaluation = evaluation._append({'model_name':str(sel_model),'accuracy': accuracy, 'f1': f1, 'precision': precision, 'recall': recall, 'roc_auc': roc_auc, 'log_loss_val': log_loss_val, 'mae': mae, 'mse': mse, 'mcc': mcc}, ignore_index=True)\n",
    "        conf_matrix = confusion_matrix(y_test, prediction)\n",
    "        tn = conf_matrix[0][0]\n",
    "        fn = conf_matrix[1][0]\n",
    "        tp = conf_matrix[1][1]\n",
    "        fp = conf_matrix[0][1]\n",
    "        conf_matrix_df = conf_matrix_df._append({'model': sel_model, 'true_negative': tn, 'false_positive': fp, 'false_negative': fn, 'true_positive': tp}, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "678dabae-11e0-455e-8f4b-db0a53c85ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(models,model,sel_model,epoch,loopno,X_train,y_train,X_test,y_test,X_train_rnn,X_test_rnn,evaluation,conf_matrix_df):\n",
    "    X= X_train\n",
    "    y= y_train\n",
    "    if sel_model == models[0]:\n",
    "        model=models[0]\n",
    "    elif sel_model == models[1]:\n",
    "        model=models[1]\n",
    "    elif sel_model == models[2]:\n",
    "        model=models[2]\n",
    "    elif sel_model == models[3]:\n",
    "        model=models[3]\n",
    "    elif sel_model == models[4]:\n",
    "        model=models[4]\n",
    "    elif sel_model == models[5]:\n",
    "        model=models[5]\n",
    "    elif sel_model == models[6]:\n",
    "        model=models[6]\n",
    "    else:\n",
    "        evaldl(models,model,sel_model,epoch,loopno,X_train,y_train,X_test,y_test,X_train_rnn,X_test_rnn,evaluation,conf_matrix_df)\n",
    "        return\n",
    "    for loop in range(loopno):\n",
    "        model.fit(X,y)\n",
    "        prediction=model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, prediction)\n",
    "        f1 = f1_score(y_test, prediction)\n",
    "        precision = precision_score(y_test, prediction)\n",
    "        recall = recall_score(y_test, prediction)\n",
    "        roc_auc = roc_auc_score(y_test, prediction)\n",
    "        log_loss_val = log_loss(y_test, prediction)\n",
    "        mae = mean_absolute_error(y_test, prediction)\n",
    "        mse = mean_squared_error(y_test, prediction)\n",
    "        mcc = matthews_corrcoef(y_test, prediction)\n",
    "        evaluation = evaluation._append({'model_name':str(sel_model),'accuracy': accuracy, 'f1': f1, 'precision': precision, 'recall': recall, 'roc_auc': roc_auc, 'log_loss_val': log_loss_val, 'mae': mae, 'mse': mse, 'mcc': mcc}, ignore_index=True)\n",
    "        conf_matrix = confusion_matrix(y_test, prediction)\n",
    "        tn = conf_matrix[0][0]\n",
    "        fn = conf_matrix[1][0]\n",
    "        tp = conf_matrix[1][1]\n",
    "        fp = conf_matrix[0][1]\n",
    "        conf_matrix_df = conf_matrix_df._append({'model': sel_model, 'true_negative': tn, 'false_positive': fp, 'false_negative': fn, 'true_positive': tp}, ignore_index=True)\n",
    "    return evaluation,conf_matrix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b3fcddc4-b25a-427f-b484-6e67e35ff5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14156\\818212735.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  evaluation = evaluation._append({'model_name':str(sel_model),'accuracy': accuracy, 'f1': f1, 'precision': precision, 'recall': recall, 'roc_auc': roc_auc, 'log_loss_val': log_loss_val, 'mae': mae, 'mse': mse, 'mcc': mcc}, ignore_index=True)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[86], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m models:\n\u001b[1;32m----> 2\u001b[0m     ev,con \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m(models,model,n,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,X_train,y_train,X_test,y_test,X_train_rnn,X_test_rnn,evaluation,conf_matrix_df)\n\u001b[0;32m      3\u001b[0m     str1\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mProject\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mEXPERIMENTS\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mNew folder\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mevaluation\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mevaluated\u001b[39m\u001b[38;5;124m\"\u001b[39m,n,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m     str2\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mProject\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mEXPERIMENTS\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mNew folder\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mevaluation\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mconfusion-matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m,n,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "for n in models:\n",
    "    ev,con = eval(models,model,n,1,1,X_train,y_train,X_test,y_test,X_train_rnn,X_test_rnn,evaluation,conf_matrix_df)\n",
    "    str1=r\"C:\\Users\\user\\Desktop\\Project\\EXPERIMENTS\\models\\New folder\\evaluation\\evaluated\",n,\".csv\"\n",
    "    str2=r\"C:\\Users\\user\\Desktop\\Project\\EXPERIMENTS\\models\\New folder\\evaluation\\confusion-matrix\",n,\".csv\"\n",
    "    evaluation.to_csv(str1,index=True)\n",
    "    conf_matrix_df.to_csv(str2,index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65fd868-cd85-4902-8e7f-c1aacb8e5ee3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
