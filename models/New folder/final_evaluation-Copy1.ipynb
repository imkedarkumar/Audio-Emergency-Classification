{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc76452-dbd7-4270-bd7f-45a79b0328ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.models as models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, SimpleRNN, Dropout, GRU\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, confusion_matrix, log_loss, mean_absolute_error, mean_squared_error, matthews_corrcoef\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\user\\Desktop\\Project\\EXPERIMENTS\\revised-data\\audio_features_cp.csv\")\n",
    "\n",
    "# Define feature columns and target column\n",
    "x_cols = ['mfcc_1', 'mfcc_2', 'mfcc_3', 'mfcc_4', 'mfcc_5', 'mfcc_6', 'mfcc_7', 'mfcc_8', \n",
    "           'mfcc_9', 'mfcc_10', 'mfcc_11', 'mfcc_12', 'mfcc_13', 'spectral_centroid', \n",
    "           'spectral_bandwidth', 'zero_crossing_rate', 'spectrogram_mean', 'spectrogram_median', 'spectrogram_variance']\n",
    "y_cols = ['label']\n",
    "\n",
    "# Normalize the feature data to range [0,1] using MinMaxScaler\n",
    "SMM = MinMaxScaler(feature_range=(0, 1))\n",
    "df[x_cols] = SMM.fit_transform(df[x_cols])\n",
    "\n",
    "# Split data into features and labels\n",
    "X = df[x_cols].values  # Convert to NumPy array\n",
    "y = df[y_cols].values.ravel()  # Convert to 1D array\n",
    "\n",
    "# Train-test split (20% test set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train_rnn = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test_rnn = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(C=1.0, solver='lbfgs', max_iter=500, random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(criterion='entropy', max_depth=10, min_samples_split=5, min_samples_leaf=2, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(criterion='entropy', n_estimators=500, max_depth=10, min_samples_split=5, min_samples_leaf=2, random_state=42),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'SVM': SVC(C=1.0, kernel='rbf', gamma='scale', probability=True),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, min_samples_split=5, min_samples_leaf=2, random_state=42),\n",
    "    'Neural Network': Sequential([\n",
    "        Dense(128, input_shape=(X_train.shape[1],), activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ]),\n",
    "    'CNN': Sequential([\n",
    "        layers.InputLayer(input_shape=(19,)),\n",
    "        layers.Reshape((19, 1, 1)),\n",
    "        layers.Conv2D(32, kernel_size=(3, 1), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D(pool_size=(2, 1), padding='same'),\n",
    "        layers.Conv2D(64, kernel_size=(3, 1), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D(pool_size=(2, 1), padding='same'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ]),\n",
    "    'RNN': Sequential([\n",
    "        SimpleRNN(50, input_shape=(1, 19), activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ]),\n",
    "    'LSTM': Sequential([\n",
    "        LSTM(128, input_shape=(X_train_rnn.shape[1], X_train_rnn.shape[2]), activation='relu', return_sequences=False),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ]),\n",
    "    'GRU': Sequential([\n",
    "        GRU(128, input_shape=(X_train_rnn.shape[1], X_train_rnn.shape[2]), activation='relu', return_sequences=False),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Compile neural network models\n",
    "for model_name, model in models.items():\n",
    "    if model_name in ['Neural Network', 'CNN', 'RNN', 'LSTM', 'GRU']:\n",
    "        model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Evaluation and Confusion Matrix DataFrames\n",
    "eval_columns = ['model_name', 'accuracy', 'f1', 'precision', 'recall', 'roc_auc', 'log_loss_val', 'mae', 'mse', 'mcc']\n",
    "conf_matrix_columns = ['model_name', 'true_negative', 'false_positive', 'false_negative', 'true_positive']\n",
    "evaluation = pd.DataFrame(columns=eval_columns)\n",
    "conf_matrix_df = pd.DataFrame(columns=conf_matrix_columns)\n",
    "\n",
    "# Training and Evaluation Function\n",
    "def evaluate_model(model, model_name, epochs=1, loops=1):\n",
    "    for _ in range(loops):\n",
    "        # Train the model\n",
    "        if model_name in ['Neural Network', 'CNN']:\n",
    "            model.fit(X_train, y_train, epochs=epochs, batch_size=32, verbose=0)\n",
    "            y_pred_prob = model.predict(X_test)\n",
    "        elif model_name in ['RNN', 'LSTM', 'GRU']:\n",
    "            model.fit(X_train_rnn, y_train, epochs=epochs, batch_size=32, verbose=0)\n",
    "            y_pred_prob = model.predict(X_test_rnn)\n",
    "        else:\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else model.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "        metrics = {\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'f1': f1_score(y_test, y_pred),\n",
    "            'precision': precision_score(y_test, y_pred),\n",
    "            'recall': recall_score(y_test, y_pred),\n",
    "            'roc_auc': roc_auc_score(y_test, y_pred),\n",
    "            'log_loss_val': log_loss(y_test, y_pred),\n",
    "            'mae': mean_absolute_error(y_test, y_pred),\n",
    "            'mse': mean_squared_error(y_test, y_pred),\n",
    "            'mcc': matthews_corrcoef(y_test, y_pred)\n",
    "        }\n",
    "        \n",
    "        # Append evaluation metrics\n",
    "        evaluation.loc[len(evaluation)] = [model_name] + list(metrics.values())\n",
    "        \n",
    "        # Confusion matrix\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        tn, fp, fn, tp = conf_matrix.ravel()\n",
    "        conf_matrix_df.loc[len(conf_matrix_df)] = [model_name, tn, fp, fn, tp]\n",
    "\n",
    "# Execute the evaluation for each model\n",
    "for model_name, model in models.items():\n",
    "    evaluate_model(model, model_name, epochs=500, loops=100)\n",
    "\n",
    "# Save results to CSV\n",
    "evaluation.to_csv(r\"C:\\Users\\user\\Desktop\\Project\\EXPERIMENTS\\models\\New folder\\evaluation\\evaluated2.csv\", index=False)\n",
    "conf_matrix_df.to_csv(r\"C:\\Users\\user\\Desktop\\Project\\EXPERIMENTS\\models\\New folder\\evaluation\\confusion_matrix2.csv\", index=False)\n",
    "\n",
    "evaluation.head()\n",
    "\n",
    "conf_matrix_df.head()\n",
    "\n",
    "evaluation.tail()\n",
    "\n",
    "conf_matrix_df.tail()\n",
    "\n",
    "#Only Use When Needed, else, All Data Will Be Deleted.\n",
    "\n",
    "\n",
    "# evaluation=evaluation.drop(evaluation.index)\n",
    "# conf_matrix_df=conf_matrix_df.drop(conf_matrix_df.index)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
