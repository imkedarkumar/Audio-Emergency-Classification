{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea38f14d-b3c7-41a2-8896-6e8489796a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d3a1df5-e4bd-46a9-bb57-3927f546fdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\user\\Desktop\\Project\\EXPERIMENTS\\revised-data\\audio_features_cp.csv\")\n",
    "\n",
    "# Separate features and labels\n",
    "x_cols = ['mfcc_1', 'mfcc_2', 'mfcc_3', 'mfcc_4', 'mfcc_5', 'mfcc_6', 'mfcc_7', 'mfcc_8', \n",
    "           'mfcc_9', 'mfcc_10', 'mfcc_11', 'mfcc_12', 'mfcc_13', 'spectral_centroid', \n",
    "           'spectral_bandwidth', 'zero_crossing_rate', 'spectrogram_mean' , 'spectrogram_median' , 'spectrogram_variance']\n",
    "y_cols = ['label']\n",
    "\n",
    "# Scale only feature columns\n",
    "SMM = MinMaxScaler(feature_range=(0, 1))\n",
    "df[x_cols] = SMM.fit_transform(df[x_cols])\n",
    "\n",
    "X = df[x_cols]\n",
    "y = df[y_cols].values.ravel()  # Convert to 1D array for the model\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db6a136d-9fca-4a10-94f3-c81ddcc7c9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.InputLayer(input_shape=(19,)))\n",
    "\n",
    "# Reshape input to be suitable for convolution (like an image with 1 channel)\n",
    "model.add(layers.Reshape((19, 1, 1)))  # Reshape to (19, 1, 1) for CNN processing\n",
    "\n",
    "# 1st Convolutional Layer\n",
    "model.add(layers.Conv2D(32, kernel_size=(3, 1), activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 1), padding='same'))\n",
    "\n",
    "# 2nd Convolutional Layer\n",
    "model.add(layers.Conv2D(64, kernel_size=(3, 1), activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 1), padding='same'))\n",
    "\n",
    "# Flattening the output from the convolutional layers to pass into Dense layers\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# Fully Connected Layer\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "\n",
    "# Adding Dropout to prevent overfitting\n",
    "model.add(layers.Dropout(0.2))\n",
    "\n",
    "# Output Layer for binary classification (scream or non-scream)\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9a60bca-46df-4a53-91c6-d9644391b824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8898 - loss: 0.2707\n",
      "Epoch 2/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8937 - loss: 0.2626\n",
      "Epoch 3/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9086 - loss: 0.2453\n",
      "Epoch 4/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9005 - loss: 0.2646\n",
      "Epoch 5/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9253 - loss: 0.2064\n",
      "Epoch 6/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9137 - loss: 0.2211\n",
      "Epoch 7/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9159 - loss: 0.2190\n",
      "Epoch 8/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9223 - loss: 0.2100\n",
      "Epoch 9/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9182 - loss: 0.2063\n",
      "Epoch 10/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9183 - loss: 0.2012\n",
      "Epoch 11/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9272 - loss: 0.1872\n",
      "Epoch 12/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9272 - loss: 0.1934\n",
      "Epoch 13/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9269 - loss: 0.1925\n",
      "Epoch 14/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9236 - loss: 0.1889\n",
      "Epoch 15/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9349 - loss: 0.1718\n",
      "Epoch 16/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9228 - loss: 0.2007\n",
      "Epoch 17/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9309 - loss: 0.1787\n",
      "Epoch 18/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9315 - loss: 0.1656\n",
      "Epoch 19/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9293 - loss: 0.1743\n",
      "Epoch 20/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9318 - loss: 0.1881\n",
      "Epoch 21/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9300 - loss: 0.1792\n",
      "Epoch 22/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9371 - loss: 0.1681\n",
      "Epoch 23/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9311 - loss: 0.1785\n",
      "Epoch 24/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9362 - loss: 0.1643\n",
      "Epoch 25/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9440 - loss: 0.1448\n",
      "Epoch 26/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9430 - loss: 0.1524\n",
      "Epoch 27/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9381 - loss: 0.1558\n",
      "Epoch 28/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9407 - loss: 0.1515\n",
      "Epoch 29/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9413 - loss: 0.1669\n",
      "Epoch 30/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9462 - loss: 0.1460\n",
      "Epoch 31/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9449 - loss: 0.1402\n",
      "Epoch 32/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9431 - loss: 0.1372\n",
      "Epoch 33/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9432 - loss: 0.1509\n",
      "Epoch 34/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9447 - loss: 0.1447\n",
      "Epoch 35/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9448 - loss: 0.1386\n",
      "Epoch 36/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9399 - loss: 0.1548\n",
      "Epoch 37/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9382 - loss: 0.1547\n",
      "Epoch 38/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9443 - loss: 0.1451\n",
      "Epoch 39/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9421 - loss: 0.1487\n",
      "Epoch 40/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9446 - loss: 0.1461\n",
      "Epoch 41/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9400 - loss: 0.1642\n",
      "Epoch 42/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9499 - loss: 0.1266\n",
      "Epoch 43/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9484 - loss: 0.1353\n",
      "Epoch 44/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9529 - loss: 0.1377\n",
      "Epoch 45/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9549 - loss: 0.1358\n",
      "Epoch 46/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9539 - loss: 0.1230\n",
      "Epoch 47/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9486 - loss: 0.1309\n",
      "Epoch 48/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9565 - loss: 0.1146\n",
      "Epoch 49/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9518 - loss: 0.1230\n",
      "Epoch 50/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9538 - loss: 0.1207\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2b9de7f4560>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1c6a3b3-a5ae-4020-887a-1a9cf937f410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9229 - loss: 0.2115\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.24175170063972473, 0.9136363863945007]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "218ade45-0cbf-44ca-a4ba-4c75302898a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prediction Function for New Audio\n",
    "def extract_features(audio_file):\n",
    "    # Load the audio file\n",
    "    y, sr = librosa.load(audio_file, sr=None)\n",
    "    \n",
    "    # Extract MFCC (first 13 coefficients)\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    mfccs_mean = np.mean(mfccs.T, axis=0)\n",
    "    \n",
    "    # Extract Spectral Centroid\n",
    "    spectral_centroid = np.mean(librosa.feature.spectral_centroid(y=y, sr=sr))\n",
    "    \n",
    "    # Extract Spectral Bandwidth\n",
    "    spectral_bandwidth = np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr))\n",
    "    \n",
    "    # Extract Zero-Crossing Rate\n",
    "    zero_crossing_rate = np.mean(librosa.feature.zero_crossing_rate(y=y))\n",
    "    \n",
    "    # Extract Spectrogram (STFT)\n",
    "    spectrogram = np.abs(librosa.stft(y))\n",
    "    spectrogram_mean = np.mean(spectrogram.T, axis=0)  # Get mean of spectrogram along time axis\n",
    "    spectrogram_mean2 = np.mean(spectrogram_mean)\n",
    "    spectrogram_median = np.median(spectrogram_mean)\n",
    "    spectrogram_variance = np.var(spectrogram_mean)\n",
    "    \n",
    "    # Return the features as a list (order must match the training features)\n",
    "    return [\n",
    "        mfccs_mean[0], mfccs_mean[1], mfccs_mean[2], mfccs_mean[3], mfccs_mean[4],\n",
    "        mfccs_mean[5], mfccs_mean[6], mfccs_mean[7], mfccs_mean[8], mfccs_mean[9],\n",
    "        mfccs_mean[10], mfccs_mean[11], mfccs_mean[12],\n",
    "        spectral_centroid, spectral_bandwidth, zero_crossing_rate,\n",
    "        spectrogram_mean2, spectrogram_median, spectrogram_variance\n",
    "    ]\n",
    "\n",
    "# Prediction function\n",
    "def pred(aud):\n",
    "    audio = aud\n",
    "    features = extract_features(audio)\n",
    "    feature = np.array(features).reshape(1, 19)  # Correct shape\n",
    "    feature = SMM.transform(feature)  # Use transform instead of fit_transform\n",
    "    predis = model.predict(feature)\n",
    "    \n",
    "    if (predis > 0.5):\n",
    "        print(\"Screaming\")\n",
    "    else:\n",
    "        print(\"Non_screaming\")\n",
    "        \n",
    "    print(predis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e125a00-4df8-4c89-b3e5-4b018558a3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Non_screaming\n",
      "[[0.262057]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ipt = r\"C:\\Users\\user\\Desktop\\Project\\EXPERIMENTS\\testaudio\\test5.wav\"\n",
    "pred(ipt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4486c4-c642-44c6-9c51-9590f22ee52a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
